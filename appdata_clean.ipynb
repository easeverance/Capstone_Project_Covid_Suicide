{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e88aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, classification_report\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from scipy.stats import norm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ee7b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Westjohn\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (12,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data As Of</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Group</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>State</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>COVID-19 Deaths</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Pneumonia Deaths</th>\n",
       "      <th>Pneumonia and COVID-19 Deaths</th>\n",
       "      <th>Influenza Deaths</th>\n",
       "      <th>Footnote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/24/2021</td>\n",
       "      <td>01-01-2020</td>\n",
       "      <td>11/20/2021</td>\n",
       "      <td>By Total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>All Sexes</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>7,73,812</td>\n",
       "      <td>62,94,875</td>\n",
       "      <td>6,95,560</td>\n",
       "      <td>3,99,005</td>\n",
       "      <td>9,451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/24/2021</td>\n",
       "      <td>01-01-2020</td>\n",
       "      <td>11/20/2021</td>\n",
       "      <td>By Total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>All Sexes</td>\n",
       "      <td>Under 1 year</td>\n",
       "      <td>151</td>\n",
       "      <td>35,550</td>\n",
       "      <td>391</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/24/2021</td>\n",
       "      <td>01-01-2020</td>\n",
       "      <td>11/20/2021</td>\n",
       "      <td>By Total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>All Sexes</td>\n",
       "      <td>0-17 years</td>\n",
       "      <td>621</td>\n",
       "      <td>62,999</td>\n",
       "      <td>1,132</td>\n",
       "      <td>170</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/24/2021</td>\n",
       "      <td>01-01-2020</td>\n",
       "      <td>11/20/2021</td>\n",
       "      <td>By Total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>All Sexes</td>\n",
       "      <td>1-4 years</td>\n",
       "      <td>68</td>\n",
       "      <td>6,606</td>\n",
       "      <td>224</td>\n",
       "      <td>19</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/24/2021</td>\n",
       "      <td>01-01-2020</td>\n",
       "      <td>11/20/2021</td>\n",
       "      <td>By Total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>All Sexes</td>\n",
       "      <td>5-14 years</td>\n",
       "      <td>199</td>\n",
       "      <td>10,500</td>\n",
       "      <td>330</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data As Of  Start Date    End Date     Group  Year  Month          State  \\\n",
       "0  11/24/2021  01-01-2020  11/20/2021  By Total   NaN    NaN  United States   \n",
       "1  11/24/2021  01-01-2020  11/20/2021  By Total   NaN    NaN  United States   \n",
       "2  11/24/2021  01-01-2020  11/20/2021  By Total   NaN    NaN  United States   \n",
       "3  11/24/2021  01-01-2020  11/20/2021  By Total   NaN    NaN  United States   \n",
       "4  11/24/2021  01-01-2020  11/20/2021  By Total   NaN    NaN  United States   \n",
       "\n",
       "         Sex     Age Group COVID-19 Deaths Total Deaths Pneumonia Deaths  \\\n",
       "0  All Sexes      All Ages        7,73,812    62,94,875         6,95,560   \n",
       "1  All Sexes  Under 1 year             151       35,550              391   \n",
       "2  All Sexes    0-17 years             621       62,999            1,132   \n",
       "3  All Sexes     1-4 years              68        6,606              224   \n",
       "4  All Sexes    5-14 years             199       10,500              330   \n",
       "\n",
       "  Pneumonia and COVID-19 Deaths Influenza Deaths Footnote  \n",
       "0                      3,99,005            9,451      NaN  \n",
       "1                            19               23      NaN  \n",
       "2                           170              189      NaN  \n",
       "3                            19               65      NaN  \n",
       "4                            65               80      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in CSV for Dataframe\n",
    "data = pd.read_csv(\"covid19.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5643bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns except the Features and Independent Data\n",
    "df = df[[\"Group\", \"Year\", \"Month\", \"State\", \"Sex\", \"Age Group\", \"COVID-19 Deaths\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6dee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for better readability\n",
    "df = df.rename({\"COVID-19 Deaths\": \"Deaths\"}, axis=1)\n",
    "df = df.rename({\"Age Group\": \"Age\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00be5050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53601 entries, 0 to 71597\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Group   53601 non-null  object \n",
      " 1   Year    51345 non-null  float64\n",
      " 2   Month   46949 non-null  float64\n",
      " 3   State   53601 non-null  object \n",
      " 4   Sex     53601 non-null  object \n",
      " 5   Age     53601 non-null  object \n",
      " 6   Deaths  53601 non-null  object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Finding out how many rows are affected by null values\n",
    "df = df[df[\"Deaths\"].notnull()]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82f3abfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group     0\n",
       "Year      0\n",
       "Month     0\n",
       "State     0\n",
       "Sex       0\n",
       "Age       0\n",
       "Deaths    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping those values and checking the removal\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d26a9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46949 entries, 8262 to 71597\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Year    46949 non-null  float64\n",
      " 1   Month   46949 non-null  float64\n",
      " 2   State   46949 non-null  object \n",
      " 3   Sex     46949 non-null  object \n",
      " 4   Age     46949 non-null  object \n",
      " 5   Deaths  46949 non-null  object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows that are not grouped by Month\n",
    "# Dropping Group column after clean\n",
    "df = df[df[\"Group\"] == \"By Month\"]\n",
    "df = df.drop(\"Group\", axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8fe32c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['All Sexes', 'Male', 'Female'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values in Sex column\n",
    "df[\"Sex\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ba2fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop All Sexes rows from the column\n",
    "df.drop(df[df['Sex'] == \"All Sexes\"].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3262091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Female'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After clean\n",
    "df[\"Sex\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "034cc5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['All Ages', 'Under 1 year', '0-17 years', '1-4 years',\n",
       "       '5-14 years', '15-24 years', '18-29 years', '25-34 years',\n",
       "       '30-39 years', '35-44 years', '40-49 years', '45-54 years',\n",
       "       '50-64 years', '55-64 years', '65-74 years', '75-84 years',\n",
       "       '85 years and over'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Age unique values\n",
    "df[\"Age\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6d36ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping All Ages rows from Age column\n",
    "df.drop(df[df['Age'] == \"All Ages\"].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "813ac906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'State', 'Sex', 'Age', 'Deaths'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaned\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c929334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for returning averaged floats for the grouped Age values\n",
    "def clean_experience(x):\n",
    "    if x == \"Under 1 year\":\n",
    "        return 1\n",
    "    if x == \"0-17 years\":\n",
    "        return 10\n",
    "    if x == \"1-4 years\":\n",
    "        return 10\n",
    "    if x == \"5-14 years\":\n",
    "        return 10\n",
    "    if x == \"15-24 years\":\n",
    "        return 20\n",
    "    if x == \"18-29 years\":\n",
    "        return 20\n",
    "    if x == \"25-34 years\":\n",
    "        return 30\n",
    "    if x == \"30-39 years\":\n",
    "        return 30\n",
    "    if x == \"35-44 years\":\n",
    "        return 40\n",
    "    if x == \"40-49 years\":\n",
    "        return 40\n",
    "    if x == \"45-54 years\":\n",
    "        return 50\n",
    "    if x == \"50-64 years\":\n",
    "        return 50\n",
    "    if x == \"55-64 years\":\n",
    "        return 60\n",
    "    if x == \"65-74 years\":\n",
    "        return 70\n",
    "    if x == \"75-84 years\":\n",
    "        return 80\n",
    "    if x == \"85 years and over\":\n",
    "        return 90\n",
    "    return float(x)\n",
    "\n",
    "# Applying function to the series\n",
    "df[\"Age\"] = df[\"Age\"].apply(clean_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e305d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing new float array\n",
    "df[\"Age\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cee9c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping United States from the State column\n",
    "df.drop(df[df['State'] == \"United States\"].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ca23f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California',\n",
       "       'Colorado', 'Connecticut', 'Delaware', 'District of Columbia',\n",
       "       'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana',\n",
       "       'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
       "       'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi',\n",
       "       'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
       "       'New Jersey', 'New Mexico', 'New York', 'New York City',\n",
       "       'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
       "       'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
       "       'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
       "       'West Virginia', 'Wisconsin', 'Wyoming', 'Puerto Rico'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values from State column\n",
    "df[\"State\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f39d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping States together into Region for exploratory feature\n",
    "\n",
    "# New England\n",
    "df[\"State\"] = df[\"State\"].replace(\"Maine\", \"New England\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Rhode Island\", \"New England\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Vermont\", \"New England\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Connecticut\", \"New England\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"New Hampshire\", \"New England\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Massachusetts\", \"New England\")\n",
    "\n",
    "# Mid Atlantic\n",
    "df[\"State\"] = df[\"State\"].replace(\"New York\", \"Mid Atlantic\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"New York City\", \"Mid Atlantic\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"New Jersey\", \"Mid Atlantic\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Pennsylvania\", \"Mid Atlantic\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"District of Columbia\", \"Mid Atlantic\")\n",
    "\n",
    "\n",
    "# Southern\n",
    "df[\"State\"] = df[\"State\"].replace(\"Virginia\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"West Virginia\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Kentucky\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Delaware\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Maryland\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"North Carolina\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"South Carolina\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Tennessee\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Arkansas\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Louisiana\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Florida\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Georgia\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Alabama\", \"Southern\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Mississippi\", \"Southern\")\n",
    "\n",
    "# Mid West\n",
    "df[\"State\"] = df[\"State\"].replace(\"Michigan\", \"Mid West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"North Dakota\", \"Mid West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"South Dakota\", \"Mid West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Iowa\", \"Mid West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Minnesota\", \"Mid West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Kansas\", \"Mid West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Nebraska\", \"Mid West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Ohio\", \"Mid West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Indiana\", \"Mid West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Illinois\", \"Mid West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Wisconsin\", \"Mid West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Missouri\", \"Mid West\")\n",
    "\n",
    "#South West\n",
    "df[\"State\"] = df[\"State\"].replace(\"Texas\", \"South West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Arizona\", \"South West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"New Mexico\", \"South West\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Oklahoma\", \"South West\")\n",
    "\n",
    "#Rocky Mountains\n",
    "df[\"State\"] = df[\"State\"].replace(\"Montana\", \"Rocky Mountains\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Idaho\", \"Rocky Mountains\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Colorado\", \"Rocky Mountains\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Utah\", \"Rocky Mountains\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Wyoming\", \"Rocky Mountains\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Nevada\", \"Rocky Mountains\")\n",
    "\n",
    "#Pacific Coastal\n",
    "df[\"State\"] = df[\"State\"].replace(\"California\", \"Pacific Coastal\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Oregon\", \"Pacific Coastal\")\n",
    "df[\"State\"] = df[\"State\"].replace(\"Washington\", \"Pacific Coastal\")\n",
    "\n",
    "#North West\n",
    "df[\"State\"] = df[\"State\"].replace(\"Alaska\", \"North West\")\n",
    "\n",
    "#Oceanic\n",
    "df[\"State\"] = df[\"State\"].replace(\"Hawaii\", \"Oceanic\")\n",
    "\n",
    "#Caribbean\n",
    "df[\"State\"] = df[\"State\"].replace(\"Puerto Rico\", \"Caribbean\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de594add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Southern', 'North West', 'South West', 'Pacific Coastal',\n",
       "       'Rocky Mountains', 'New England', 'Mid Atlantic', 'Oceanic',\n",
       "       'Mid West', 'Caribbean'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the grouping\n",
    "df[\"State\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2022c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename State to Region for clarity\n",
    "df = df.rename({\"State\": \"Region\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c1c4950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 28005 entries, 9453 to 71597\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Year    28005 non-null  float64\n",
      " 1   Month   28005 non-null  float64\n",
      " 2   Region  28005 non-null  object \n",
      " 3   Sex     28005 non-null  object \n",
      " 4   Age     28005 non-null  int64  \n",
      " 5   Deaths  28005 non-null  object \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking Dtypes to see what needs to be encoded\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ca889ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 4, 8, 6, 7, 3, 1, 5, 2, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building encoder for Region column\n",
    "le_region = LabelEncoder()\n",
    "df[\"Region\"] = le_region.fit_transform(df[\"Region\"])\n",
    "df[\"Region\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6687fb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building encoder for Sex column\n",
    "le_sex = LabelEncoder()\n",
    "df[\"Sex\"] = le_sex.fit_transform(df[\"Sex\"])\n",
    "df[\"Sex\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61680d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the commas from Deaths to replace to float values\n",
    "df[\"Deaths\"] = [float(str(i).replace(\",\", \"\")) for i in df[\"Deaths\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b866479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the features and independent value for model testing\n",
    "X = df.drop(\"Deaths\", axis=1)\n",
    "y = df[\"Deaths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d05e856f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Linear Regression model and fitting values\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d26a0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the predict module to the X features\n",
    "y_pred = linear_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a814587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.10733840420126"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the difference between the actual Death data and prediction Deaths\n",
    "error = np.sqrt(mean_squared_error(y, y_pred))\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3596289c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Decision Tree Regressor, adding a random state and fitting the values\n",
    "dec_tree_reg = DecisionTreeRegressor(random_state=1)\n",
    "dec_tree_reg.fit(X, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "638bdedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the DTR predict module to the X features\n",
    "y_pred = dec_tree_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b8fcd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.58938381766252"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the difference between the actual Death data and prediction Deaths for DTR\n",
    "error = np.sqrt(mean_squared_error(y, y_pred))\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5764487f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Random Forsest Regressor, adding same random state, and fitting the values\n",
    "random_forest_reg = RandomForestRegressor(random_state=1)\n",
    "random_forest_reg.fit(X, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c91fdb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the RFR predict module to the X features\n",
    "y_pred = random_forest_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "880acfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.74871168712677"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the difference between the actual Death data and prediction Deaths for RFR\n",
    "error = np.sqrt(mean_squared_error(y, y_pred))\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b430570d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeRegressor(random_state=1),\n",
       "             param_grid={'max_depth': [None, 2, 4, 6, 8, 10, 12]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the fit and score method of GridSearchCV on the Decision Tree Regressor\n",
    "# Using multiple max_depth parameters to test and score\n",
    "# Using Mean Squared Error scoring to find the mean squared errors of each parameter\n",
    "# Fit the GridSearchCV to the values\n",
    "max_depth = [None, 2, 4, 6, 8, 10, 12]\n",
    "params = {\"max_depth\": max_depth}\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state=1)\n",
    "gsearch = GridSearchCV(regressor, params, scoring=\"neg_mean_squared_error\")\n",
    "gsearch.fit(X, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "964dd4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.53361401192186"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add Best Estimator module to GridSearchCV and then fit the values\n",
    "# Add Predict module to the features\n",
    "# Pass the y and y_pred through the Mean Squared Error module\n",
    "regressor = gsearch.best_estimator_\n",
    "\n",
    "regressor.fit(X, y.values)\n",
    "y_pred = regressor.predict(X)\n",
    "error = np.sqrt(mean_squared_error(y, y_pred))\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c118f20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9453</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9454</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9455</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9456</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9457</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71593</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71594</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71595</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71596</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71597</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28005 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year  Month  Region  Sex  Age\n",
       "9453   2020.0    1.0       9    1    1\n",
       "9454   2020.0    1.0       9    1   10\n",
       "9455   2020.0    1.0       9    1   10\n",
       "9456   2020.0    1.0       9    1   10\n",
       "9457   2020.0    1.0       9    1   20\n",
       "...       ...    ...     ...  ...  ...\n",
       "71593  2021.0   11.0       0    0   20\n",
       "71594  2021.0   11.0       0    0   30\n",
       "71595  2021.0   11.0       0    0   30\n",
       "71596  2021.0   11.0       0    0   40\n",
       "71597  2021.0   11.0       0    0   40\n",
       "\n",
       "[28005 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features in binary and float data\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7dc586ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2020', '11', 'Mid West', 'Male', '20']], dtype='<U11')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a \"model\" array for pulling values\n",
    "X = np.array([[2020, 11, \"Mid West\", \"Male\", 20]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c744a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.02e+03, 1.10e+01, 2.00e+00, 1.00e+00, 2.00e+01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the encoded Region and Sex columns and change to float type\n",
    "\n",
    "\n",
    "X[:, 2] = le_region.transform(X[:, 2])\n",
    "X[:, 3] = le_sex.transform(X[:, 3])\n",
    "\n",
    "X = X.astype(float)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46aa7037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Westjohn\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.15690737])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab Decision Tree Regressor and add predict to the features\n",
    "y_pred = regressor.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e9daa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Pickle data file by re-opening into notebook\n",
    "with open(\"saved_pick.pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Setting encoders to the correct data series    \n",
    "regressor_loaded = data[\"model\"]\n",
    "le_region = data[\"le_region\"]\n",
    "le_sex = data[\"le_sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72f0a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Westjohn\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.15690737])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the predict module to the pickle model\n",
    "y_pred = regressor_loaded.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f898c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of independent and features for logistic modeling\n",
    "X = df.drop(\"Deaths\", axis=1)\n",
    "y = df[\"Deaths\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3379f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO BINARY Classification\n",
    "y.iloc[y > 0] = 1\n",
    "# np.sqrt(np.sum((y - np.mean(y)) **2) /len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "659620ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the train and test sets and fitting the scaler\n",
    "np.random.seed(1)\n",
    "X_train,X_test,y_train, y_test = train_test_split(X,y,test_size=0.03,random_state= 1)\n",
    "# Feature Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train) #ONLY FIT to train data!!\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22d5e8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.91      0.91       515\n",
      "         1.0       0.86      0.87      0.86       326\n",
      "\n",
      "    accuracy                           0.89       841\n",
      "   macro avg       0.89      0.89      0.89       841\n",
      "weighted avg       0.89      0.89      0.89       841\n",
      "\n",
      "0.8941736028537456\n"
     ]
    }
   ],
   "source": [
    "# Scaling and predicting the logistic regression model with the l2 penalty argument\n",
    "# L2, Ridge Regression is used to correct fitting problems with models by regularization\n",
    "# It cuts the gap on large variances with the model\n",
    "# Showing accuracy score\n",
    "logmodel_scaled = LogisticRegression(penalty='l2', solver='sag', max_iter=50)\n",
    "logmodel_scaled.fit(X_train,y_train)\n",
    "predictions_scaled = logmodel_scaled.predict(X_test)\n",
    "print(classification_report(y_test,predictions_scaled))\n",
    "print(logmodel_scaled.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c59b5195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending the logistic regressor model to the encoders and then saved to the pickle file\n",
    "data1 = {\"model\": regressor, \"le_region\": le_region, \"le_sex\": le_sex, \n",
    "         \"logestic_model\": logmodel_scaled, \"scaler_model\": scaler}\n",
    "\n",
    "with open(\"saved_pick.pkl\", \"wb\") as file:\n",
    "    pickle.dump(data1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "542ca794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Westjohn\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.90909091, 0.22222222, 1.        , 0.66292135]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the model array template and then fitting to the scaler\n",
    "X = np.array([[2020, 11, \"Mid West\", \"Male\", 60]])\n",
    "\n",
    "X[:, 2] = le_region.transform(X[:, 2])\n",
    "X[:, 3] = le_sex.transform(X[:, 3])\n",
    "X = scaler.transform(X)\n",
    "X = X.astype(float)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67aafaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12458538454123835"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted probability with the model scaled\n",
    "logmodel_scaled.predict_proba(X)[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a6c20e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6156995957926077"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*norm.cdf(0.87) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637d427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
